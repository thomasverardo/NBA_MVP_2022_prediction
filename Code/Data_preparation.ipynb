{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SENZA QUELLI CON MENO DI 40 PARTITE GIOCATE\n",
    "# DATA PREPARATION\n",
    "with open(\"player_stats.pkl\", \"rb\") as f:\n",
    "    total_stats = pickle.load(f)\n",
    "#tolgo seasons che non ci servono\n",
    "total_stats = total_stats[total_stats[\"SEASON_ID\"] > 2003]\n",
    "total_stats = total_stats[total_stats[\"SEASON_ID\"] < 2022]\n",
    "#sposto la colonna MVP per prima per comodita\n",
    "cols = total_stats.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "total_stats = total_stats[cols]\n",
    "\n",
    "total_stats[\"GP\"] = total_stats[\"GP\"].astype('int')\n",
    "total_stats[\"FGM\"] = total_stats[\"FGM\"].astype('int')\n",
    "total_stats[\"FGA\"] = total_stats[\"FGA\"].astype('int')\n",
    "total_stats[\"FG3M\"] = total_stats[\"FG3M\"].astype('int')\n",
    "total_stats[\"FG3A\"] = total_stats[\"FG3A\"].astype('int')\n",
    "total_stats[\"FTM\"] = total_stats[\"FTM\"].astype('int')\n",
    "total_stats[\"FTA\"] = total_stats[\"FTA\"].astype('int')\n",
    "total_stats[\"OREB\"] = total_stats[\"OREB\"].astype('int')\n",
    "total_stats[\"DREB\"] = total_stats[\"DREB\"].astype('int')\n",
    "total_stats[\"REB\"] = total_stats[\"REB\"].astype('int')\n",
    "total_stats[\"AST\"] = total_stats[\"AST\"].astype('int')\n",
    "total_stats[\"STL\"] = total_stats[\"STL\"].astype('int')\n",
    "total_stats[\"BLK\"] = total_stats[\"BLK\"].astype('int')\n",
    "total_stats[\"TOV\"] = total_stats[\"TOV\"].astype('int')\n",
    "total_stats[\"PF\"] = total_stats[\"PF\"].astype('int')\n",
    "total_stats[\"PTS\"] = total_stats[\"PTS\"].astype('int')\n",
    "\n",
    "total_stats = total_stats[total_stats[\"GP\"] > 40]\n",
    "\n",
    "\n",
    "#divido il dataset\n",
    "season_2021 = total_stats[total_stats[\"SEASON_ID\"] == 2021]\n",
    "\n",
    "#creo nuovo dataframe per i modelli\n",
    "df = total_stats[total_stats[\"SEASON_ID\"] < 2021]\n",
    "\n",
    "#separo labels da features\n",
    "labels = df['MVP']\n",
    "features = df.drop('MVP', axis=1)\n",
    "#divido train e test --> dobbiamo decidere grandezza test set\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.20, random_state=42)\n",
    "#standardizzazione i nostri dati per anno\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_cols = df.columns\n",
    "num_cols = num_cols.drop([\"MVP\", 'CONF_RANK', 'PLAYER_ID', 'SEASON_ID', 'TEAM_ID'])\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "train_data = pd.concat([train_data, train_features], axis=0, ignore_index=True)\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "test_data = pd.concat([test_data, test_features], axis=0, ignore_index=True)\n",
    "\n",
    "for year in train_data[\"SEASON_ID\"].unique().tolist():\n",
    "    for col in num_cols.tolist():\n",
    "        a = scaler.fit_transform(train_features.loc[train_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "        train_data.loc[train_data['SEASON_ID'] == year, col] = scaler.fit_transform(train_features.loc[train_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        test_data.loc[test_data['SEASON_ID'] == year, col] = scaler.transform(test_features.loc[test_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "\n",
    "train_l = pd.DataFrame()\n",
    "train_l = pd.concat([train_l, train_labels], axis=0, ignore_index=True)\n",
    "\n",
    "#correlation matrix solo del training e tolgo quelle piu correlate\n",
    "train = pd.DataFrame()\n",
    "train = pd.concat([train_l, train_data], axis=1, ignore_index=False)\n",
    "\n",
    "train = train.rename(columns={0: \"MVP\"})\n",
    "\n",
    "X_corr = train_data.corr()\n",
    "corr_names = set()\n",
    "\n",
    "for i in range(len(X_corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(X_corr.iloc[j, i]) > 0.9:\n",
    "            col = X_corr.columns[i]\n",
    "            corr_names.add(col)\n",
    "\n",
    "train_data.drop(columns=corr_names, inplace=True)\n",
    "test_data.drop(columns=corr_names, inplace=True)\n",
    "\n",
    "# le features tolte con correlazione maggiore di 0.9 sono:{'FG3A', 'FGA', 'FTA', 'PTS', 'REB'}\n",
    "\n",
    "## SMOTE\n",
    "train.drop(columns=corr_names, inplace=True)\n",
    "training_data = train  #Mettere solo Train e non test\n",
    "\n",
    "mvp = training_data[\"MVP\"]\n",
    "\n",
    "data_to_over = training_data.drop([\"MVP\", \"PLAYER_ID\", \"SEASON_ID\", \"TEAM_ID\", \"PLAYER_AGE\"], axis=1)\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.5, random_state=23)\n",
    "X, y = oversample.fit_resample(data_to_over, mvp)\n",
    "\n",
    "over_train_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "\n",
    "#Save Over_train_data\n",
    "with open(\"Data/train_data_40.pkl\", 'wb') as f:\n",
    "    pickle.dump(over_train_data, f)\n",
    "with open(\"Data/test_data_40.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# without all players (no <40 filter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/numpy/core/getlimits.py\u001B[0m in \u001B[0;36m__new__\u001B[0;34m(cls, dtype)\u001B[0m\n\u001B[1;32m    458\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 459\u001B[0;31m             \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumeric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    460\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1393/1406880194.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0myear\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"SEASON_ID\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mcol\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnum_cols\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         \u001B[0ma\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'SEASON_ID'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0myear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m         \u001B[0mtrain_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'SEASON_ID'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0myear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtrain_features\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'SEASON_ID'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0myear\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcol\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36mfit_transform\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    850\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0my\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    851\u001B[0m             \u001B[0;31m# fit method of arity 1 (unsupervised transformation)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 852\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    853\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    854\u001B[0m             \u001B[0;31m# fit method of arity 2 (supervised transformation)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    804\u001B[0m         \u001B[0;31m# Reset internal state before fitting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    805\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 806\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpartial_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    807\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    808\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mpartial_fit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36mpartial_fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    942\u001B[0m             \u001B[0;31m# Extract the list of near constant features on the raw variances,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    943\u001B[0m             \u001B[0;31m# before taking the square root.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 944\u001B[0;31m             constant_mask = _is_constant_feature(\n\u001B[0m\u001B[1;32m    945\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvar_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_samples_seen_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    946\u001B[0m             )\n",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36m_is_constant_feature\u001B[0;34m(var, mean, n_samples)\u001B[0m\n\u001B[1;32m     76\u001B[0m     \"\"\"\n\u001B[1;32m     77\u001B[0m     \u001B[0;31m# In scikit-learn, variance is always computed using float64 accumulators.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m     \u001B[0meps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meps\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0mupper_bound\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mn_samples\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0meps\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mvar\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mmean\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m**\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/numpy/core/getlimits.py\u001B[0m in \u001B[0;36m__new__\u001B[0;34m(cls, dtype)\u001B[0m\n\u001B[1;32m    460\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    461\u001B[0m             \u001B[0;31m# In case a float instance was given\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m             \u001B[0mdtype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnumeric\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    463\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m         \u001B[0mobj\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_finfo_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "#SENZA QUELLI CON MENO DI 40 PARTITE GIOCATE\n",
    "# DATA PREPARATION\n",
    "with open(\"player_stats.pkl\", \"rb\") as f:\n",
    "    total_stats = pickle.load(f)\n",
    "#tolgo seasons che non ci servono\n",
    "total_stats = total_stats[total_stats[\"SEASON_ID\"] > 2003]\n",
    "total_stats = total_stats[total_stats[\"SEASON_ID\"] < 2022]\n",
    "#sposto la colonna MVP per prima per comodita\n",
    "cols = total_stats.columns.tolist()\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "total_stats = total_stats[cols]\n",
    "\n",
    "total_stats[\"GP\"] = total_stats[\"GP\"].astype('int')\n",
    "total_stats[\"FGM\"] = total_stats[\"FGM\"].astype('int')\n",
    "total_stats[\"FGA\"] = total_stats[\"FGA\"].astype('int')\n",
    "total_stats[\"FG3M\"] = total_stats[\"FG3M\"].astype('int')\n",
    "total_stats[\"FG3A\"] = total_stats[\"FG3A\"].astype('int')\n",
    "total_stats[\"FTM\"] = total_stats[\"FTM\"].astype('int')\n",
    "total_stats[\"FTA\"] = total_stats[\"FTA\"].astype('int')\n",
    "total_stats[\"OREB\"] = total_stats[\"OREB\"].astype('int')\n",
    "total_stats[\"DREB\"] = total_stats[\"DREB\"].astype('int')\n",
    "total_stats[\"REB\"] = total_stats[\"REB\"].astype('int')\n",
    "total_stats[\"AST\"] = total_stats[\"AST\"].astype('int')\n",
    "total_stats[\"STL\"] = total_stats[\"STL\"].astype('int')\n",
    "total_stats[\"BLK\"] = total_stats[\"BLK\"].astype('int')\n",
    "total_stats[\"TOV\"] = total_stats[\"TOV\"].astype('int')\n",
    "total_stats[\"PF\"] = total_stats[\"PF\"].astype('int')\n",
    "total_stats[\"PTS\"] = total_stats[\"PTS\"].astype('int')\n",
    "\n",
    "\n",
    "#divido il dataset\n",
    "season_2021 = total_stats[total_stats[\"SEASON_ID\"] == 2021]\n",
    "\n",
    "#creo nuovo dataframe per i modelli\n",
    "df = total_stats[total_stats[\"SEASON_ID\"] < 2021]\n",
    "\n",
    "#separo labels da features\n",
    "labels = df['MVP']\n",
    "features = df.drop('MVP', axis=1)\n",
    "#divido train e test --> dobbiamo decidere grandezza test set\n",
    "\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.20, random_state=42)\n",
    "#standardizzazione i nostri dati per anno\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "num_cols = df.columns\n",
    "num_cols = num_cols.drop([\"MVP\", 'CONF_RANK', 'PLAYER_ID', 'SEASON_ID', 'TEAM_ID'])\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "train_data = pd.concat([train_data, train_features], axis=0, ignore_index=True)\n",
    "\n",
    "test_data = pd.DataFrame()\n",
    "test_data = pd.concat([test_data, test_features], axis=0, ignore_index=True)\n",
    "\n",
    "for year in train_data[\"SEASON_ID\"].unique().tolist():\n",
    "    for col in num_cols.tolist():\n",
    "        a = scaler.fit_transform(train_features.loc[train_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "        train_data.loc[train_data['SEASON_ID'] == year, col] = scaler.fit_transform(train_features.loc[train_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "\n",
    "        test_data.loc[test_data['SEASON_ID'] == year, col] = scaler.transform(test_features.loc[test_features['SEASON_ID'] == year, col].to_numpy().reshape(-1, 1))\n",
    "\n",
    "train_l = pd.DataFrame()\n",
    "train_l = pd.concat([train_l, train_labels], axis=0, ignore_index=True)\n",
    "\n",
    "#correlation matrix solo del training e tolgo quelle piu correlate\n",
    "train = pd.DataFrame()\n",
    "train = pd.concat([train_l, train_data], axis=1, ignore_index=False)\n",
    "\n",
    "train = train.rename(columns={0: \"MVP\"})\n",
    "\n",
    "X_corr = train_data.corr()\n",
    "corr_names = set()\n",
    "\n",
    "for i in range(len(X_corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(X_corr.iloc[j, i]) > 0.9:\n",
    "            col = X_corr.columns[i]\n",
    "            corr_names.add(col)\n",
    "\n",
    "train_data.drop(columns=corr_names, inplace=True)\n",
    "test_data.drop(columns=corr_names, inplace=True)\n",
    "\n",
    "# le features tolte con correlazione maggiore di 0.9 sono:{'FG3A', 'FGA', 'FTA', 'PTS', 'REB'}\n",
    "\n",
    "## SMOTE\n",
    "train.drop(columns=corr_names, inplace=True)\n",
    "training_data = train  #Mettere solo Train e non test\n",
    "\n",
    "mvp = training_data[\"MVP\"]\n",
    "\n",
    "data_to_over = training_data.drop([\"MVP\", \"PLAYER_ID\", \"SEASON_ID\", \"TEAM_ID\", \"PLAYER_AGE\"], axis=1)\n",
    "\n",
    "oversample = SMOTE(sampling_strategy=0.5, random_state=23)\n",
    "X, y = oversample.fit_resample(data_to_over, mvp)\n",
    "\n",
    "over_train_data = pd.concat([X, y], axis=1)\n",
    "\n",
    "\n",
    "#Save Over_train_data\n",
    "with open(\"Data/train_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(over_train_data, f)\n",
    "\n",
    "#test_data[] AGGIUNGERE TEST LABELS CON TEST DATA\n",
    "with open(\"Data/test_data.pkl\", 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}